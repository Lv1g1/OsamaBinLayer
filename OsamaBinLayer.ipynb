{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "\n",
    "from flax import linen as nn\n",
    "from flax.training import train_state\n",
    "\n",
    "import optax\n",
    "\n",
    "SEED = 0\n",
    "rng = jax.random.PRNGKey(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ByteClassifier(nn.Module):\n",
    "    num_bytes: int\n",
    "    embedding_dim: int\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, inputs, train=True):\n",
    "        # Input: (batch_size, num_bytes) of raw byte values (0-255)\n",
    "        x = nn.Embed(256, self.embedding_dim)(inputs.astype(jnp.int32))  # Ensure integers\n",
    "\n",
    "        # Temporal convolution to capture local patterns\n",
    "        x = nn.Conv(features=64, kernel_size=(5,), padding='SAME')(x)\n",
    "        x = nn.relu(x)\n",
    "\n",
    "        # Attention layer to focus on important positions\n",
    "        attn = nn.SelfAttention(num_heads=4)(x)\n",
    "        x = jnp.concatenate([x, attn], axis=-1)\n",
    "\n",
    "        # Final dense layers with dropout\n",
    "        x = nn.Dense(64)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dropout(0.3, deterministic=not train)(x, rng=rng)\n",
    "\n",
    "        # Output layer\n",
    "        x = nn.Dense(1)(x)\n",
    "        return nn.sigmoid(x).squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "def create_model():\n",
    "    return ByteClassifier(\n",
    "        num_bytes=256,  # Example: analyze 256-byte chunks\n",
    "        embedding_dim=16\n",
    "    )\n",
    "\n",
    "# Create initial state\n",
    "def initialize_model(key, input_shape=(256,)):\n",
    "    model = create_model()\n",
    "    dummy_input = jnp.zeros((1, *input_shape), dtype=jnp.int32)  # Ensure integers\n",
    "    params = model.init(key, dummy_input)['params']\n",
    "    return model, params\n",
    "\n",
    "def create_optimizer(learning_rate=1e-3):\n",
    "    return optax.adamw(\n",
    "        learning_rate=learning_rate,\n",
    "        b1=0.9,\n",
    "        b2=0.999,\n",
    "        weight_decay=1e-5\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "model, params = initialize_model(rng)\n",
    "optimizer = create_optimizer(1e-3)\n",
    "state = train_state.TrainState.create(\n",
    "    apply_fn=model.apply,\n",
    "    params=params,\n",
    "    tx=optimizer\n",
    ")\n",
    "\n",
    "def loss_fn(params, inputs, labels, overestimate_weight=1.0, underestimate_weight=1.0):\n",
    "    # Forward pass: Calculate logits (predictions)\n",
    "    logits = model.apply({'params': params}, inputs)\n",
    "    print(logits.shape)\n",
    "    \n",
    "    # Calculate error: (prediction - true label)\n",
    "    error = logits - labels\n",
    "    \n",
    "    # Apply different weights for overestimating and underestimating errors\n",
    "    overestimating_error = (error > 0)  # True when overestimated (logits > labels)\n",
    "    underestimating_error = (error < 0)  # True when underestimated (logits < labels)\n",
    "    \n",
    "    # Compute MSE for each case\n",
    "    mse_overestimating = jnp.where(overestimating_error, (error ** 2) * overestimate_weight, 0)\n",
    "    mse_underestimating = jnp.where(underestimating_error, (error ** 2) * underestimate_weight, 0)\n",
    "    \n",
    "    # Total loss: sum of weighted MSE errors for both types\n",
    "    total_loss = jnp.mean(mse_overestimating + mse_underestimating)\n",
    "    \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def train_step(state, batch):\n",
    "    inputs, labels = batch\n",
    "    grad_fn = jax.value_and_grad(loss_fn)\n",
    "    loss, grads = grad_fn(state.params, inputs, labels)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    return state, loss\n",
    "\n",
    "def sliding_window_data(sequence, window_size, step_size=1):\n",
    "    inputs, labels = [], []\n",
    "    for i in range(0, len(sequence) - window_size + 1, step_size):\n",
    "        input_window = sequence[i:i + window_size]\n",
    "        label_window = sequence[i:i + window_size] \n",
    "        inputs.append(input_window)\n",
    "        labels.append(label_window)\n",
    "    \n",
    "    return inputs, labels\n",
    "\n",
    "def train_model(state, sequence, window_size=10, step_size=1, num_epochs=10):\n",
    "    # Generate sliding windows for inputs and labels\n",
    "    inputs, labels = sliding_window_data(sequence, window_size, step_size)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for batch_inputs, batch_labels in zip(inputs, labels):\n",
    "            batch = (batch_inputs, batch_labels)  # Prepare batch\n",
    "            state, loss = train_step(state, batch)\n",
    "            epoch_loss += loss\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {epoch_loss/len(inputs):.4f}\")\n",
    "    \n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\"\"\"\n",
    "    {\n",
    "        script_name: {\n",
    "            \"bytes\": [[252], [72, ... 240] ... [104, 126, 162, 208, 83]],\n",
    "            \"data_addresses\": [48, 50, 52, ... 526, 528]\n",
    "        }\n",
    "\n",
    "        ...\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "def load_data(path):\n",
    "    with open(path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        \n",
    "    for script_name, script_data in data.items():\n",
    "        try:\n",
    "            bytes = script_data['bytes']\n",
    "            flattened_bytes = [b for instruction in bytes for b in instruction]\n",
    "            \n",
    "            data_addresses = script_data['data_addresses']\n",
    "            \n",
    "            x = jnp.array(flattened_bytes)\n",
    "            \n",
    "            y = np.zeros_like(x)\n",
    "            y[data_addresses] = 1\n",
    "            y = jnp.array(y)\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        yield script_name, x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_path = 'payloads_dict.json'\n",
    "exec_data = list(load_data(data_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(571,) (571,)\n"
     ]
    }
   ],
   "source": [
    "data = (exec_data[0][1], exec_data[0][2])\n",
    "print(data[0].shape, data[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/luigi/Documents/megaprogetto/OsamaBinLayer.ipynb Cella 9\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/luigi/Documents/megaprogetto/OsamaBinLayer.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Train model\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/luigi/Documents/megaprogetto/OsamaBinLayer.ipynb#X20sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m state \u001b[39m=\u001b[39m train_model(state, data, window_size\u001b[39m=\u001b[39;49m\u001b[39m256\u001b[39;49m, step_size\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, num_epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n",
      "\u001b[1;32m/home/luigi/Documents/megaprogetto/OsamaBinLayer.ipynb Cella 9\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/luigi/Documents/megaprogetto/OsamaBinLayer.ipynb#X20sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m         state, loss \u001b[39m=\u001b[39m train_step(state, batch)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/luigi/Documents/megaprogetto/OsamaBinLayer.ipynb#X20sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m         epoch_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/luigi/Documents/megaprogetto/OsamaBinLayer.ipynb#X20sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mnum_epochs\u001b[39m}\u001b[39;00m\u001b[39m - Loss: \u001b[39m\u001b[39m{\u001b[39;00mepoch_loss\u001b[39m/\u001b[39;49m\u001b[39mlen\u001b[39;49m(inputs)\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/luigi/Documents/megaprogetto/OsamaBinLayer.ipynb#X20sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mreturn\u001b[39;00m state\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "state = train_model(state, data, window_size=256, step_size=1, num_epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
